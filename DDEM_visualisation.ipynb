{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002b8ee-313a-44e4-98eb-180d49419ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import HBox, Label, IntSlider,IntRangeSlider\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import clear_output\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, CircleMarker, Popup, Polyline, Polygon, LayerGroup, LayersControl,ScaleControl, FullScreenControl\n",
    "from ipyleaflet import WidgetControl\n",
    "from ipywidgets import interactive\n",
    "import matplotlib as mpl\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, Label, IntSlider,IntRangeSlider\n",
    "#import matplotlib.patches as patches\n",
    "#from matplotlib.patches import Polygon\n",
    "import matplotlib\n",
    "import matplotlib.colors\n",
    "import contextily as cx\n",
    "import shapely.geometry as sg\n",
    "from rijksdriehoek import rijksdriehoek\n",
    "from matplotlib.collections import PatchCollection\n",
    "import ipympl\n",
    "import warnings\n",
    "import numpy as np\n",
    "import ast\n",
    "import datetime as dt\n",
    "import time as t\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "RD = rijksdriehoek.Rijksdriehoek()\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "MAX_GROUP_SIZE = 250\n",
    "GPKG_VIS_MAP = {}\n",
    "if os.path.exists(\"Data/gpkg_vis_map.txt\"):\n",
    "    f = open(\"Data/gpkg_vis_map.txt\")\n",
    "    GPKG_VIS_MAP = eval(f.read())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f95202-077a-4bdb-846b-748674bfbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_KNMI_file(filename):\n",
    "    f = open(filename)\n",
    "    data = f.read().split('\\n')\n",
    "    f.close()\n",
    "    start_idx = None\n",
    "    for i in range(len(data)):\n",
    "        if '# STN,YYYYMMDD' in data[i]:\n",
    "            start_idx = i + 2\n",
    "            break\n",
    "    headers = data[start_idx-2].split(',')\n",
    "    headers = [h.strip() for h in headers]\n",
    "    evapo_id = headers.index('EV24')\n",
    "    date_id = headers.index('YYYYMMDD')\n",
    "    precip_id = headers.index('RH')\n",
    "    temp_id = headers.index('TX')\n",
    "    processed_data = {}\n",
    "    for row in data[start_idx:]:\n",
    "        if row != '':\n",
    "            split_row = row.split(',')\n",
    "            date = dt.datetime.strptime(split_row[date_id].strip(), '%Y%m%d')\n",
    "            if '' not in [date, split_row[evapo_id].strip(), split_row[precip_id].strip(), split_row[temp_id].strip()]:\n",
    "                if '348' in filename and date.year < 1988: # very incomplete data before 1988\n",
    "                    continue\n",
    "                processed_data[date] = [eval(split_row[precip_id].strip()),\n",
    "                                        eval(split_row[evapo_id].strip()),\n",
    "                                        eval(split_row[temp_id].strip())]\n",
    "                if processed_data[date][0] == -1:\n",
    "                    processed_data[date][0] = 0\n",
    "                processed_data[date][0] /= 10\n",
    "                processed_data[date][1] /= 10\n",
    "                processed_data[date][2] /= 10\n",
    "    return processed_data\n",
    "\n",
    "def get_yearfrac(date):\n",
    "    year = eval(date[:4])\n",
    "    month = eval(date[5:7].lstrip('0'))\n",
    "    day = eval(date[8:].lstrip('0'))\n",
    "    dayOfYear = dt.datetime(year=year, month=month, day=day) - dt.datetime(year=year, month=1, day=1)\n",
    "    yearDays = dt.datetime(year=year+1, month=1, day=1) - dt.datetime(year=year, month=1, day=1)\n",
    "    yearfrac = year + dayOfYear.days / yearDays.days\n",
    "    return yearfrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d770b3-2b68-47b0-a216-5038934c67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = '2015-01-02'\n",
    "Cabauw = read_KNMI_file(f'Data/etmgeg_348.txt')\n",
    "tmax = max(Cabauw.keys())\n",
    "tmax = '{:0>4d}-{:0>2d}-{:0>2d}'.format(tmax.year, tmax.month, tmax.day)\n",
    "tmin = min(Cabauw.keys()) + dt.timedelta(days=365) # to give space for tau to run back\n",
    "tmin = '{:0>4d}-{:0>2d}-{:0>2d}'.format(tmin.year, tmin.month, tmin.day)\n",
    "etmgeg = Cabauw \n",
    "\n",
    "tmin_yf = get_yearfrac(tmin)\n",
    "tmax_yf = get_yearfrac(tmax)\n",
    "t0_yf = get_yearfrac(t0)\n",
    "t0_dt = dt.datetime.strptime(t0, '%Y-%m-%d')\n",
    "tmin_dt = dt.datetime.strptime(tmin, '%Y-%m-%d')\n",
    "tmax_dt = dt.datetime.strptime(tmax, '%Y-%m-%d')\n",
    "\n",
    "t_eval_min = dt.datetime(1945, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e76cb-1ab2-4a3e-aef6-78dcd1ace17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spams10(filename, savename=\"Data/spams10_delfland.txt\"):\n",
    "    print(f\"Processing {filename}...\")\n",
    "    if os.path.exists(savename):\n",
    "        f = open(savename)\n",
    "        data = f.read()\n",
    "        f.close()\n",
    "        data_dict = eval(data)\n",
    "    else:\n",
    "        data_spams10 = pd.read_parquet(filename)\n",
    "        data_dict = {}\n",
    "        for idx in range(len(data_spams10[data_spams10.columns[0]])):\n",
    "            data_dict[idx] = {}\n",
    "            for col in data_spams10.columns:\n",
    "                data_dict[idx][col] = data_spams10[col][idx]\n",
    "            data_dict[idx][\"pnt_crd\"] = (data_dict[idx][\"pnt_lon\"], data_dict[idx][\"pnt_lat\"])\n",
    "            RD.from_wgs(data_dict[idx][\"pnt_lat\"], data_dict[idx][\"pnt_lon\"])\n",
    "            data_dict[idx][\"center_dec\"] = (int(RD.rd_x), int(RD.rd_y))\n",
    "            data_dict[idx][\"model_mode\"] = \"SPAMS_default\"\n",
    "            data_dict[idx][\"has_InSAR\"] = True\n",
    "            data_dict[idx][\"has_surfaceleveling\"] = False\n",
    "            \n",
    "            for key in ['h2015_m', 'sigma_h2015_m', #'h2023_m', 'v_mpy', 'sigma_v_mpy', \n",
    "                       'xI_mpy', 'sigma_xI_mpy', 'xI_frac_1000pct', \n",
    "                       'mean_yearly_irreversible_subsidence_MYIS_mpy', 'sigma_MYIS_mpy',\n",
    "                       'xP_mpmm', 'sigma_xP_mpmm', 'xE_mpmm', 'sigma_xE_mpmm', 'tau_kd', 'sigma_tau_kd',\n",
    "                       'rho_h2015_xI_1000', 'rho_h2015_xP_1000', 'rho_h2015_xE_1000', 'rho_h2015_tau_1000',\n",
    "                       'rho_xI_xP_1000', 'rho_xI_xE_1000', 'rho_xI_tau_1000', \n",
    "                       'rho_xP_xE_1000', 'rho_xP_tau_1000', \n",
    "                       'rho_xE_tau_1000',\n",
    "                       'timespan_ky', 'n_observations_1000', \n",
    "                       'significant_irreversible_subsidence_detected_2s_1000', 'significant_irreversible_subsidence_detected_3s_1000', \n",
    "                       'discriminatory_power_2s_1000pct', \n",
    "                       'discriminatory_power_3s_1000pct', 'MDD_80p_mpy', \n",
    "                       'cum_irreversible_subsidence_since_2000_m', 'oldest_observation_ky', \n",
    "                       'OMT_sust_2s_1000', 'OMT_sust_3s_1000', 'F_value_norm']:\n",
    "                if key in [\"h2015_m\", \"sigma_h2015_m\",'rho_h2015_xI_1000', 'rho_h2015_xP_1000', 'rho_h2015_xE_1000', 'rho_h2015_tau_1000',\n",
    "                          'rho_xI_tau_1000', 'rho_xP_tau_1000', 'rho_xE_tau_1000', 'significant_irreversible_subsidence_detected_2s_1000', 'significant_irreversible_subsidence_detected_3s_1000',\n",
    "                          'timespan_ky', 'discriminatory_power_2s_1000pct', 'discriminatory_power_3s_1000pct', 'MDD_80p_mpy',\n",
    "                          'cum_irreversible_subsidence_since_2000_m', 'oldest_observation_ky',\n",
    "                          'OMT_sust_2s_1000', 'OMT_sust_3s_1000', 'F_value_norm', 'sigma_tau_kd']:\n",
    "                    data_dict[idx][key] = None\n",
    "                elif key == \"xI_mpy\":\n",
    "                    data_dict[idx][key] = data_dict[idx][\"xI\"] * 365.2425 / 1000\n",
    "                elif key == \"sigma_xI_mpy\":\n",
    "                    data_dict[idx][key] = np.sqrt(data_dict[idx][\"var_xI\"]) * 365.2425 / 1000\n",
    "                elif key in [\"xP_mpmm\", \"xE_mpmm\", \"tau_kd\"]:\n",
    "                    data_dict[idx][key] = data_dict[idx][key.split(\"_\")[0]] / 1000\n",
    "                elif key in [\"sigma_xP_mpmm\", \"sigma_xE_mpmm\"]:\n",
    "                    data_dict[idx][key] = np.sqrt(data_dict[idx][\"var_\" + key.split(\"_\")[1]]) / 1000\n",
    "                elif key in ['rho_xI_xP_1000', 'rho_xI_xE_1000', 'rho_xP_xE_1000']:\n",
    "                    build_key = \"cov_\"\n",
    "                    mult = 1\n",
    "                    if \"xP\" in key:\n",
    "                        build_key += \"xP\"\n",
    "                    if \"xE\" in key:\n",
    "                        build_key += \"xE\"\n",
    "                    if \"xI\" in key:\n",
    "                        build_key += \"xI\"\n",
    "                        mult = 365.2425\n",
    "                    data_dict[idx][key] = data_dict[idx][build_key] * mult / 1e9 / np.sqrt(data_dict[idx][\"var_\" + key.split(\"_\")[1]]) / np.sqrt(data_dict[idx][\"var_\" + key.split(\"_\")[2]])\n",
    "                elif key == \"n_observations_1000\":\n",
    "                    data_dict[idx][key] = data_dict[idx][\"dof\"] + 3\n",
    "                elif key == \"xI_frac_1000pct\":\n",
    "                \n",
    "                    ndays = (tmax_dt-tmin_dt).days\n",
    "                \n",
    "                    R_array = np.zeros((ndays, ))\n",
    "                    t0_idx = None\n",
    "                \n",
    "                    for day in range(ndays):\n",
    "                        for backwards_day in range(int(data_dict[idx][\"tau\"])+1):\n",
    "                            cur_day = tmin_dt + dt.timedelta(days=day-backwards_day)\n",
    "                            try:\n",
    "                                Pt = etmgeg[cur_day][0]\n",
    "                                Et = etmgeg[cur_day][1]\n",
    "                                if backwards_day == int(data_dict[idx][\"tau\"]):\n",
    "                                    R_array[day] += (Pt*data_dict[idx][\"xP\"] - Et*data_dict[idx][\"xE\"]) * (data_dict[idx][\"tau\"] % 1)\n",
    "                                else:\n",
    "                                    R_array[day] += (Pt*data_dict[idx][\"xP\"] - Et*data_dict[idx][\"xE\"])\n",
    "                \n",
    "                            except KeyError:\n",
    "                                continue\n",
    "                    data_dict[idx][key] = (sum(1*R_array<=0)/R_array.shape[0]) * 100 / 1000\n",
    "                elif key == \"mean_yearly_irreversible_subsidence_MYIS_mpy\":\n",
    "                    data_dict[idx][key] = data_dict[idx][\"xI_frac_1000pct\"] * 10 * data_dict[idx][\"xI_mpy\"]\n",
    "                elif key == \"sigma_MYIS_mpy\":\n",
    "                    data_dict[idx][key] = data_dict[idx][\"xI_frac_1000pct\"] * 10 * data_dict[idx][\"sigma_xI_mpy\"]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unhandled key {key}!\")\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"{idx+1}/{len(data_spams10[data_spams10.columns[0]])}\")\n",
    "        f = open(savename, \"w\")\n",
    "        f.write(str(data_dict))\n",
    "        f.close()\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def add_vis_gpkg_parameters(vis_gpkg, gpkg_data):\n",
    "    ct = 0\n",
    "    for EUP in list(gpkg_data.keys()):\n",
    "        txt_eup = map_index(EUP)\n",
    "        vis_eup = map_vis_index(EUP)  \n",
    "        if vis_eup is not None:\n",
    "            if False:\n",
    "                t, h = plot_model(txt_eup)\n",
    "                y, yt, ys = get_data(txt_eup)\n",
    "                EUP_f = open(f'Data/EUPs/{txt_eup}.txt')\n",
    "                raw = EUP_f.read()\n",
    "                EUP_f.close()\n",
    "                raw_EUP = raw.replace('nan', \"'nan'\").replace('array', 'np.array')\n",
    "                EUP_data = eval(raw_EUP)\n",
    "        \n",
    "                yhat = [h[t.index(yt_)] for yt_ in yt]\n",
    "                ehat = np.array(yhat) - np.array(y)\n",
    "                T_stat = np.sum(ehat ** 2 / np.array(ys) ** 2)\n",
    "                if EUP_data[\"model_mode\"] == \"SPAMS\":\n",
    "                    nu = int(1000*vis_data[vis_eup]['n_observations_1000']) - 5\n",
    "                    vis_gpkg[vis_eup][\"has_InSAR\"] = True\n",
    "                else:\n",
    "                    nu = int(1000*vis_data[vis_eup]['n_observations_1000']) - 2\n",
    "                    vis_gpkg[vis_eup][\"has_InSAR\"] = False\n",
    "                if nu == 0:\n",
    "                    T_stat_norm = 1000000\n",
    "                else:\n",
    "                    T_stat_norm = T_stat / nu\n",
    "                vis_gpkg[vis_eup][\"F_value_norm\"] = T_stat_norm\n",
    "\n",
    "                if min(yt) < 1995:\n",
    "                    vis_gpkg[vis_eup][\"has_surfaceleveling\"] = True\n",
    "                else:\n",
    "                    vis_gpkg[vis_eup][\"has_surfaceleveling\"] = False\n",
    "\n",
    "            vis_gpkg[vis_eup][\"center_dec\"] = (int(np.mean([ii[0] for ii in vis_gpkg[vis_eup][\"crd_dec\"][0]])),\n",
    "                                               int(np.mean([ii[1] for ii in vis_gpkg[vis_eup][\"crd_dec\"][0]])))\n",
    "\n",
    "\n",
    "        ct += 1\n",
    "        if ct % 1000 == 0:\n",
    "            print(f\"{ct}/{len(list(gpkg_data.keys()))}\")\n",
    "    return vis_gpkg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f726a-b4b9-4400-bac7-a1c37154002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gpkg(filename):\n",
    "    \n",
    "    assert '.' in filename, f'Filename {filename} does not have an extension!'    \n",
    "    if filename.split('.')[1] != 'gpkg':\n",
    "        raise ValueError(f'Expected gpkg, got {filename}')\n",
    "    if not os.path.isfile(f'Data/{filename}'):\n",
    "        raise ValueError(f'File {filename} not found in Data directory!')\n",
    "    \n",
    "    AOI = {}\n",
    "    with fiona.open(f\"Data/{filename}\") as layer:\n",
    "        for feature in layer:     \n",
    "            AOI[feature['properties']['ogc_fid']] = {\n",
    "                \"crd_dec\": [feature['geometry']['coordinates'][ii] for ii in range(len(feature['geometry']['coordinates']))]\n",
    "                }\n",
    "            for key in ['h0', 's_h0', 'xI', 's_xI', 'xP', 's_xP', 'xE', 's_xE', 'tau', 's_tau',\n",
    "                        'rho_xIh0', 'rho_xPh0', 'rho_xEh0', 'rho_tauh0',\n",
    "                        'rho_xPxI', 'rho_xExI', 'rho_xItau', \n",
    "                        'rho_xPxE', 'rho_xPtau', \n",
    "                        'rho_xEtau', 'xI_frac']:\n",
    "                AOI[feature['properties']['ogc_fid']][key] = feature['properties'][key]\n",
    "    return AOI\n",
    "\n",
    "def read_visualisation_gpkg(filename):\n",
    "    assert '.' in filename, f'Filename {filename} does not have an extension!'    \n",
    "    if filename.split('.')[1] != 'gpkg':\n",
    "        raise ValueError(f'Expected gpkg, got {filename}')\n",
    "    if not os.path.isfile(f'Data/{filename}'):\n",
    "        raise ValueError(f'File {filename} not found in Data directory!')\n",
    "    \n",
    "    AOI = {}\n",
    "    with fiona.open(f\"Data/{filename}\") as layer:\n",
    "        for feature in layer:     \n",
    "            AOI[feature['properties']['ogc_fid']] = {\n",
    "                \"crd_dec\": [feature['geometry']['coordinates'][ii] for ii in range(len(feature['geometry']['coordinates']))]\n",
    "                }\n",
    "            for key in ['h2015_m', 'sigma_h2015_m', #'h2023_m', 'v_mpy', 'sigma_v_mpy', \n",
    "                   'xI_mpy', 'sigma_xI_mpy', 'xI_frac_1000pct', \n",
    "                   'mean_yearly_irreversible_subsidence_MYIS_mpy', 'sigma_MYIS_mpy',\n",
    "                   'xP_mpmm', 'sigma_xP_mpmm', 'xE_mpmm', 'sigma_xE_mpmm', 'tau_kd', 'sigma_tau_kd',\n",
    "                   'rho_h2015_xI_1000', 'rho_h2015_xP_1000', 'rho_h2015_xE_1000', 'rho_h2015_tau_1000',\n",
    "                   'rho_xI_xP_1000', 'rho_xI_xE_1000', 'rho_xI_tau_1000', \n",
    "                   'rho_xP_xE_1000', 'rho_xP_tau_1000', \n",
    "                   'rho_xE_tau_1000',\n",
    "                   'timespan_ky', 'n_observations_1000', \n",
    "                   'significant_irreversible_subsidence_detected_2s_1000', 'significant_irreversible_subsidence_detected_3s_1000', \n",
    "                   'discriminatory_power_2s_1000pct', \n",
    "                   'discriminatory_power_3s_1000pct', 'MDD_80p_mpy', \n",
    "                   'cum_irreversible_subsidence_since_2000_m', 'oldest_observation_ky', \n",
    "                   'OMT_sust_2s_1000', 'OMT_sust_3s_1000']:\n",
    "                AOI[feature['properties']['ogc_fid']][key] = feature['properties'][key]\n",
    "    return AOI\n",
    "\n",
    "def convert_wgs84_to_rd(list_of_coords):\n",
    "    \"\"\"\n",
    "    Converts a list of coordinates in WGS84 to RD\n",
    "    :param list_of_coords: list of (lon, lat) objects\n",
    "    :return: list of (rd_x, rd_y) objects\n",
    "    \"\"\"\n",
    "    rd_coords = []\n",
    "    for coord in list_of_coords:\n",
    "        RD.from_wgs(lon=coord[0], lat=coord[1])\n",
    "        rd_coords.append([RD.rd_x, RD.rd_y])\n",
    "    return rd_coords\n",
    "\n",
    "def convert_rd_to_wgs84(list_of_coords):\n",
    "    \"\"\"\n",
    "    Converts a list of coordinates in RD to WGS\n",
    "    :param list_of_coords: list of (rdx, rdy) objects\n",
    "    :return: list of (lon, lat) objects\n",
    "    \"\"\"\n",
    "    wgs_coords = []\n",
    "    for coord in list_of_coords:\n",
    "        RD.rd_x = coord[0]\n",
    "        RD.rd_y = coord[1]\n",
    "        wgs_coords.append(RD.to_wgs())\n",
    "    return wgs_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2355ef-cbc1-4a2b-903a-2c6de1c018a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aoi():\n",
    "    filename = \"Data/AoI_GreenHeart-polygon.shp\"\n",
    "    shape = fiona.open(filename)\n",
    "    finished = False\n",
    "    shape_iter = iter(shape)\n",
    "    aoi_rd_poly = None\n",
    "    while not finished:\n",
    "        try:\n",
    "            shp = next(shape_iter)\n",
    "            polygons = [sg.Polygon(convert_wgs84_to_rd(shp[\"geometry\"][\"coordinates\"][ii])) for ii in range(len(shp[\"geometry\"][\"coordinates\"]))]\n",
    "            if len(polygons) > 1 or aoi_rd_poly is not None:\n",
    "                raise ValueError(\"Cannot handle AOI with more than 1 polygon!\")\n",
    "            aoi_rd_poly = polygons[0]\n",
    "            if not aoi_rd_poly.is_valid:\n",
    "                raise ValueError(\"Invalid polygon AOI!\")\n",
    "        except StopIteration:\n",
    "            finished = True\n",
    "    if aoi_rd_poly is None:\n",
    "        raise ValueError(f\"No valid AOI polygon found in {filename}!\")\n",
    "    return convert_rd_to_wgs84(np.array(aoi_rd_poly.exterior.coords.xy).T)\n",
    "aoi_wgs_poly = read_aoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf299f-a905-4f02-b441-f357462febc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    EUP_f = open(f'Data/EUPs/{file}.txt')\n",
    "    raw = EUP_f.read()\n",
    "    EUP_f.close()\n",
    "    raw_EUP = raw.replace('nan', \"'nan'\").replace('array', 'np.array')\n",
    "    EUP = eval(raw_EUP)\n",
    "\n",
    "    if EUP['InSAR'] != -999:\n",
    "        for keykey in [k for k in EUP['InSAR'].keys() if k[0] == 'h']:\n",
    "            for d in range(len(EUP['InSAR'][keykey])):\n",
    "                if EUP['InSAR'][keykey][d] == 'nan':\n",
    "                    EUP['InSAR'][keykey][d] = np.nan\n",
    "\n",
    "    \n",
    "    y = []\n",
    "    y_insar = []\n",
    "    t = []\n",
    "    t_insar = []\n",
    "    s = []\n",
    "    s_insar = []\n",
    "    min_t = None\n",
    "    max_t = None\n",
    "\n",
    "    if EUP['EUP_type'] == 'brp':\n",
    "        for key in ['100_AHN1', '100_AHN2', '100_AHN3', '100_AHN4', '_ThMD']:\n",
    "            if EUP[f't{key}'] not in [-999, '']:\n",
    "                y.append(EUP[f'h{key}'])\n",
    "                t.append(EUP[f't{key}'])\n",
    "                s.append(max(EUP[f's{key}'], 0.001))\n",
    "\n",
    "        if EUP['InSAR'] != -999:\n",
    "            keys = [key[1:] for key in EUP['InSAR'].keys() if key[0] == 't']\n",
    "            for key in keys:\n",
    "                for t_ in range(len(EUP['InSAR'][f't{key}'])):\n",
    "                    if not np.isnan(EUP['InSAR'][f'h{key}'][t_]):\n",
    "                        t_insar.append(EUP['InSAR'][f't{key}'][t_])\n",
    "                        y_insar.append(EUP['InSAR'][f'h{key}'][t_])\n",
    "                        s_insar.append(0.01)\n",
    "\n",
    "    else:\n",
    "        for key in ['100_AHN1', '100_AHN2', '100_AHN3', '100_AHN4', '_ThMD']:\n",
    "            if EUP[f't{key}'] not in [-999, '']:\n",
    "                y.append(EUP[f'h{key}'])\n",
    "                t.append(EUP[f't{key}'])\n",
    "                s.append(EUP[f's{key}'])\n",
    "    full_y = []\n",
    "    full_t = []\n",
    "    full_s = []\n",
    "    for d in range(len(y)):\n",
    "        full_y.append(y[d])\n",
    "        full_t.append(get_yearfrac(t[d]))\n",
    "        full_s.append(s[d])\n",
    "    for d in range(len(y_insar)):\n",
    "        full_y.append(y_insar[d]+EUP['h0'])\n",
    "        full_t.append(get_yearfrac(t_insar[d]))\n",
    "        full_s.append(s_insar[d])\n",
    "    return full_y, full_t, full_s\n",
    "\n",
    "def plot_model(file, mode=\"DDEM\"):\n",
    "    if mode == \"DDEM\":\n",
    "        EUP_f = open(f'Data/EUPs/{file}.txt')\n",
    "        raw = EUP_f.read()\n",
    "        EUP_f.close()\n",
    "        raw_EUP = raw.replace('nan', \"'nan'\").replace('array', 'np.array')\n",
    "        EUP = eval(raw_EUP)\n",
    "    \n",
    "        if EUP['InSAR'] != -999:\n",
    "            for keykey in [k for k in EUP['InSAR'].keys() if k[0] == 'h']:\n",
    "                for d in range(len(EUP['InSAR'][keykey])):\n",
    "                    if EUP['InSAR'][keykey][d] == 'nan':\n",
    "                        EUP['InSAR'][keykey][d] = np.nan\n",
    "    \n",
    "        xI = EUP['xI']\n",
    "        xP = EUP['xP']\n",
    "        xE = EUP['xE']\n",
    "        h0 = EUP['h0']\n",
    "        tau = EUP['tau']\n",
    "    else:\n",
    "        xI = file[\"xI\"]\n",
    "        xP = file[\"xP\"]\n",
    "        xE = file[\"xE\"]\n",
    "        h0 = 0\n",
    "        tau = file[\"tau\"]\n",
    "\n",
    "    tt = []\n",
    "    h = []\n",
    "    cur_t = t_eval_min\n",
    "    while get_yearfrac('{:0>4d}-{:0>2d}-{:0>2d}'.format(cur_t.year, cur_t.month, cur_t.day)) < tmax_yf:\n",
    "        tt.append('{:0>4d}-{:0>2d}-{:0>2d}'.format(cur_t.year, cur_t.month, cur_t.day))\n",
    "        cur_t += dt.timedelta(days=1)\n",
    "\n",
    "    ndays = (tmax_dt-tmin_dt).days\n",
    "\n",
    "    R_array = np.zeros((ndays, ))\n",
    "    I_array = np.zeros((ndays, ))\n",
    "    t_array = np.zeros((ndays, ))\n",
    "    t0_idx = None\n",
    "\n",
    "    for day in range(ndays):\n",
    "        for backwards_day in range(int(tau)+1):\n",
    "            cur_day = tmin_dt + dt.timedelta(days=day-backwards_day)\n",
    "            try:\n",
    "                Pt = etmgeg[cur_day][0]\n",
    "                Et = etmgeg[cur_day][1]\n",
    "                if backwards_day == int(tau):\n",
    "                    R_array[day] += (Pt*xP - Et*xE) * (tau % 1)\n",
    "                else:\n",
    "                    R_array[day] += (Pt*xP - Et*xE)\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        if R_array[day] <= 0:\n",
    "            I_array[day] = I_array[day-1] + xI\n",
    "        else:\n",
    "            I_array[day] = I_array[day-1]\n",
    "\n",
    "        date = tmin_dt + dt.timedelta(days=day)\n",
    "        t_array[day] = get_yearfrac('{:0>4d}-{:0>2d}-{:0>2d}'.format(date.year, date.month, date.day))\n",
    "        if date == t0_dt:\n",
    "            t0_idx = day\n",
    "\n",
    "    t_lst = list(t_array)\n",
    "    if t0_idx is None:\n",
    "        raise ValueError('t0 > tmax!')\n",
    "\n",
    "    xIfrac = sum(1*R_array<=0)/R_array.shape[0]\n",
    "\n",
    "    R_array -= R_array[t0_idx]\n",
    "    I_array -= I_array[t0_idx]\n",
    "\n",
    "\n",
    "    for t in tt:\n",
    "        if get_yearfrac(t) < tmin_yf:\n",
    "            elev = h0 + R_array[0] + I_array[0] + (dt.datetime.strptime(t, '%Y-%m-%d') - tmin_dt).days * xI * xIfrac\n",
    "        else:\n",
    "            tidx = t_lst.index(get_yearfrac(t))\n",
    "            elev = h0 + R_array[tidx]+I_array[tidx]\n",
    "        h.append(elev)\n",
    "\n",
    "    return [get_yearfrac(t) for t in tt], h\n",
    "\n",
    "def convert_value_to_hex(value, vmin=-10, vmax=10):\n",
    "    pct = min(max((value - vmin) / (vmax - vmin), 0), 1)\n",
    "    clr = (int(255 * min(1, 2 - 2 * pct)), \n",
    "           int(255 * (1 - 2 * abs(0.5 - pct))), \n",
    "           int(255 * min(1, 2 * pct)))\n",
    "    #clr = (int(255 * max(0, (1 - 2 * pct))), 0, (int(255 * max(2*pct - 1, 0))))\n",
    "    hx = '#'\n",
    "    for c in clr:\n",
    "        hx += \"{:0>2s}\".format(hex(c)[2:])\n",
    "    return hx\n",
    "\n",
    "def map_index(EUP):\n",
    "    \"\"\"\n",
    "    This function maps the index of the gpkg EUP to the txt EUP, as these are not the same:\n",
    "    the gpkg maintains the original numbering before ~50000 EUPs were removed, the txt EUP\n",
    "    starts counting from 0 without gaps\n",
    "    :param EUP: the gpkg index of the EUP\n",
    "    :return: the txt index of the EUP\n",
    "    \"\"\"\n",
    "    keys = list(gpkg_data.keys())\n",
    "    # print(keys.index(EUP))\n",
    "    return keys.index(EUP)\n",
    "\n",
    "def map_vis_index(EUP):\n",
    "    \"\"\"\n",
    "    This function maps the index of the gpkg EUP to the visualisation EUP, as these are not the same:\n",
    "    the gpkg maintains the original numbering before ~50000 EUPs were removed, the visualisation EUP\n",
    "    starts counting from 0 without gaps and has EUPs with no data removed\n",
    "    :param EUP: the gpkg index of the EUP\n",
    "    :return: the vis index of the EUP\n",
    "    \"\"\" \n",
    "    if EUP in GPKG_VIS_MAP.keys():\n",
    "        return GPKG_VIS_MAP[EUP]\n",
    "    vis_id = None\n",
    "    start_id = map_index(EUP)\n",
    "    for att_id in range(start_id, 0, -1):\n",
    "        if att_id in vis_data.keys():\n",
    "            if gpkg_data[EUP]['crd_dec'] == vis_data[att_id]['crd_dec']:\n",
    "                vis_id = att_id\n",
    "                break\n",
    "    GPKG_VIS_MAP[EUP] = vis_id\n",
    "    f = open(\"Data/gpkg_vis_map.txt\", \"w\")\n",
    "    f.write(str(GPKG_VIS_MAP))\n",
    "    f.close()\n",
    "    return vis_id\n",
    "\n",
    "def convert_gpkg_to_wgs84(gpkg):\n",
    "    for EUP in gpkg.keys():\n",
    "        gpkg[EUP]['crd_wgs'] = convert_rd_to_wgs84(gpkg_data[EUP]['crd_dec'][0])\n",
    "    return gpkg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7609a-1fce-45a8-be3f-b665b74ec872",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpkg_data = read_gpkg('InSAR_ALS_GNSS_Grav_Leveling.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608fda5-4223-4dcb-bc57-8e8cae8603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = read_visualisation_gpkg('Visualisation_export.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8d08c-9089-439e-9698-b06d6b1645b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_data = add_vis_gpkg_parameters(vis_data, gpkg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc0c97-991c-4097-9aaf-f63605fdc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquets = glob.glob(\"Data/SPAMS10/*.parquet\")\n",
    "nkeys = 0\n",
    "spams10_data = {}\n",
    "for parquet in parquets:\n",
    "    pqt_data = read_spams10(parquet, f'''Data/SPAMS10_processed/{parquet.split(\"/\")[-1].split(\".\")[0]}.txt''')\n",
    "    for key in pqt_data.keys():\n",
    "        spams10_data[nkeys] = {}\n",
    "        for key2 in pqt_data[key].keys():\n",
    "            spams10_data[nkeys][key2] = pqt_data[key][key2]\n",
    "        nkeys += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767bfe09-7182-46ce-8aed-409d052f4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpkg_data = convert_gpkg_to_wgs84(gpkg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14406c6f-8123-4879-aaba-95bf4e28ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output()\n",
    "\n",
    "out1 = widgets.Output()\n",
    "out2 = widgets.Output()\n",
    "out3 = widgets.Output()\n",
    "out4 = widgets.Output()\n",
    "out5 = widgets.Output()\n",
    "out6 = widgets.Output()\n",
    "\n",
    "tab = widgets.Tab(children = [out1, out2])\n",
    "tab.set_title(0, 'Estimated Model')\n",
    "tab.set_title(1, 'Unused')\n",
    "\n",
    "tab2 = widgets.Tab(children = [out3, out4])\n",
    "tab2.set_title(0, 'Parameters')\n",
    "tab2.set_title(1, 'Unused')\n",
    "\n",
    "tab3 = widgets.Tab(children = [out5])\n",
    "tab3.set_title(0, 'Map colorbar')\n",
    "\n",
    "tab4 = widgets.Tab(children = [out6])\n",
    "tab4.set_title(0, \"Search bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba1f49-d3c4-41b9-9dcb-9bec562b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "CarDB = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "CarDB.base = True\n",
    "CarDB.name = 'Map (CartoDB)'\n",
    "\n",
    "m = Map(center=list(np.mean(np.array(aoi_wgs_poly), axis=0)), zoom=12, min_zoom=12, close_popup_on_click=False , layers = [CarDB])\n",
    "\n",
    "AoI = LayerGroup(name = 'AoI')        \n",
    "\n",
    "line = Polyline(locations = aoi_wgs_poly,\n",
    "            weight = 2,\n",
    "            color= '#000000', linestyle='--', fill=False) \n",
    "\n",
    "highlighter = Polyline(locations = [[0, 0], [0, 0]],\n",
    "                       weight=3,\n",
    "                       color='#5abf4d', fill=False, name='Selection')\n",
    "\n",
    "AoI.add_layer(line)\n",
    "highlighter_group = LayerGroup(name=\"highlighter\")\n",
    "highlighter_group.add_layer(highlighter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8cf82-ecc1-48a3-9337-e18b348e30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(EUP, m):\n",
    "    def button_click(**kwargs):\n",
    "        # clear_output(wait=True)\n",
    "        if isinstance(EUP, str):\n",
    "            # it's spams10\n",
    "            spams10_EUP = eval(EUP.split(\"_\")[1])\n",
    "            data = {\"model_mode\": \"SPAMS_default\"}\n",
    "            highlighter.locations = [[spams10_data[spams10_EUP][\"pnt_crd\"][1]+3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]+3e-4],\n",
    "                                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]-3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]+3e-4],\n",
    "                                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]-3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]-3e-4],\n",
    "                                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]+3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]-3e-4],\n",
    "                                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]+3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]+3e-4]]\n",
    "            t, h = plot_model({\"xI\": spams10_data[spams10_EUP][\"xI_mpy\"] / 365.2425,\n",
    "                               \"xP\": spams10_data[spams10_EUP][\"xP_mpmm\"],\n",
    "                               \"xE\": spams10_data[spams10_EUP][\"xE_mpmm\"],\n",
    "                               \"tau\": spams10_data[spams10_EUP][\"tau_kd\"] * 1000},\n",
    "                              mode=\"SPAMS10\")\n",
    "        else:\n",
    "            txt_eup = map_index(EUP)\n",
    "            vis_eup = map_vis_index(EUP)                        \n",
    "            t, h = plot_model(txt_eup)\n",
    "            y, yt, ys = get_data(txt_eup)\n",
    "            EUP_f = open(f'Data/EUPs/{txt_eup}.txt')\n",
    "            raw = EUP_f.read()\n",
    "            EUP_f.close()\n",
    "            raw_EUP = raw.replace('nan', \"'nan'\").replace('array', 'np.array')\n",
    "            data = eval(raw_EUP)\n",
    "            highlighter.locations = convert_rd_to_wgs84(gpkg_data[EUP]['crd_dec'][0])\n",
    "    \n",
    "            yhat = [h[t.index(yt_)] for yt_ in yt]\n",
    "            ehat = np.array(yhat) - np.array(y)\n",
    "            T_stat = np.sum(ehat ** 2 / np.array(ys) ** 2)\n",
    "            if vis_eup is not None:\n",
    "                if data[\"model_mode\"] == \"SPAMS\":\n",
    "                    nu = int(1000*vis_data[vis_eup]['n_observations_1000']) - 5\n",
    "                else:\n",
    "                    nu = int(1000*vis_data[vis_eup]['n_observations_1000']) - 2\n",
    "                T_stat_norm = T_stat / nu\n",
    "        \n",
    "        with out1:\n",
    "            try:\n",
    "                plt.close(fig=\"Spatial unit timeseries\")\n",
    "            except:\n",
    "                pass\n",
    "            clear_output(wait=True)\n",
    "            if data[\"model_mode\"] != \"SPAMS_default\":\n",
    "                print(\"Red lines indicate 1-sigma standard deviation\")\n",
    "            plt.figure(figsize=(11,5), num=\"Spatial unit timeseries\")\n",
    "            plt.plot(t, h, label='Model fit')\n",
    "            if data[\"model_mode\"] != \"SPAMS_default\":\n",
    "                plt.errorbar(yt, y, yerr=ys, fmt='o', ecolor='r', label='Observations')\n",
    "            plt.grid(True)\n",
    "            plt.xlabel('Time [y]')\n",
    "            if data[\"model_mode\"] == \"SPAMS_default\":\n",
    "                plt.ylabel('Elevation change\\nw.r.t. 1 Jan 2015 [m]')\n",
    "            else:\n",
    "                plt.ylabel('Elevation [m - NAP]')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        with out3:\n",
    "            clear_output(wait=True)\n",
    "            if data[\"model_mode\"] != \"SPAMS_default\":\n",
    "                if vis_eup is None:\n",
    "                    print('This spatial unit was filtered out of the resulting dataset due to a failed model estimate')\n",
    "                else:\n",
    "                    nsigfig_xi_raw = np.log10(vis_data[vis_eup]['sigma_xI_mpy']*1000)\n",
    "                    if nsigfig_xi_raw < 0:\n",
    "                        nsigfig = int(np.ceil(-1 * nsigfig_xi_raw) + 1)\n",
    "                        xi_disp = round(vis_data[vis_eup]['xI_mpy']*1000, nsigfig)\n",
    "                        sxi_disp = round(vis_data[vis_eup]['sigma_xI_mpy']*1000, nsigfig)\n",
    "                        msr_disp = round(vis_data[vis_eup]['mean_yearly_irreversible_subsidence_MYIS_mpy']*1000, nsigfig)\n",
    "                        smsr_disp = round(vis_data[vis_eup]['sigma_MYIS_mpy']*1000, nsigfig)\n",
    "                    elif nsigfig_xi_raw < 1:\n",
    "                        xi_disp = round(vis_data[vis_eup]['xI_mpy']*1000, 1)\n",
    "                        sxi_disp = round(vis_data[vis_eup]['sigma_xI_mpy']*1000, 1)\n",
    "                        msr_disp = round(vis_data[vis_eup]['mean_yearly_irreversible_subsidence_MYIS_mpy']*1000, 1)\n",
    "                        smsr_disp = round(vis_data[vis_eup]['sigma_MYIS_mpy']*1000, 1)\n",
    "                    else:\n",
    "                        xi_disp = round(vis_data[vis_eup]['xI_mpy']*1000, 0)\n",
    "                        sxi_disp = round(vis_data[vis_eup]['sigma_xI_mpy']*1000, 0)  \n",
    "                        msr_disp = round(vis_data[vis_eup]['mean_yearly_irreversible_subsidence_MYIS_mpy']*1000, 0)\n",
    "                        smsr_disp = round(vis_data[vis_eup]['sigma_MYIS_mpy']*1000, 0)\n",
    "    \n",
    "                    if data['model_mode'] in [\"SPAMS\", \"SPAMS_default\"]:\n",
    "                        nsigfig_xp_raw = np.log10(vis_data[vis_eup]['sigma_xP_mpmm']*1000)\n",
    "                        if nsigfig_xp_raw < 0:\n",
    "                            nsigfig = int(np.ceil(-1 * nsigfig_xp_raw) + 1)\n",
    "                            xp_disp = round(vis_data[vis_eup]['xP_mpmm']*1000, nsigfig)\n",
    "                            sxp_disp = round(vis_data[vis_eup]['sigma_xP_mpmm']*1000, nsigfig)\n",
    "                        elif nsigfig_xp_raw < 1:\n",
    "                            xp_disp = round(vis_data[vis_eup]['xP_mpmm']*1000, 1)\n",
    "                            sxp_disp = round(vis_data[vis_eup]['sigma_xP_mpmm']*1000, 1)\n",
    "                        else:\n",
    "                            xp_disp = round(vis_data[vis_eup]['xP_mpmm']*1000, 0)\n",
    "                            sxp_disp = round(vis_data[vis_eup]['sigma_xP_mpmm']*1000, 0)  \n",
    "    \n",
    "                        nsigfig_xe_raw = np.log10(vis_data[vis_eup]['sigma_xE_mpmm']*1000)\n",
    "                        if nsigfig_xe_raw < 0:\n",
    "                            nsigfig = int(np.ceil(-1 * nsigfig_xe_raw) + 1)\n",
    "                            xe_disp = round(vis_data[vis_eup]['xE_mpmm']*1000, nsigfig)\n",
    "                            sxe_disp = round(vis_data[vis_eup]['sigma_xE_mpmm']*1000, nsigfig)\n",
    "                        elif nsigfig_xe_raw < 1:\n",
    "                            xe_disp = round(vis_data[vis_eup]['xE_mpmm']*1000, 1)\n",
    "                            sxe_disp = round(vis_data[vis_eup]['sigma_xE_mpmm']*1000, 1)\n",
    "                        else:\n",
    "                            xe_disp = round(vis_data[vis_eup]['xE_mpmm']*1000, 0)\n",
    "                            sxe_disp = round(vis_data[vis_eup]['sigma_xE_mpmm']*1000, 0) \n",
    "                        if data[\"model_mode\"] == \"SPAMS\":\n",
    "                            print(f'''GPKG spatial unit {EUP} (TXT {txt_eup}, VIS {vis_eup})\n",
    "----------\n",
    "Estimated parameters ({data['model_mode'] + ('-extended' if data['model_mode'] == 'SPAMS' else '')} model)\n",
    "\n",
    "Elevation (1 Jan 2015): {round(vis_data[vis_eup]['h2015_m'], 3)}±{round(vis_data[vis_eup]['sigma_h2015_m'], 3)} m - NAP\n",
    "XI (irreversible): {xi_disp}±{sxi_disp} mm/y ({round(vis_data[vis_eup]['xI_frac_1000pct']*1000, 1)}% active)\n",
    "XP (precipitation): {xp_disp}±{sxp_disp} mm/mm\n",
    "XE (evapotranspiration): {xe_disp}±{sxe_disp} mm/mm\n",
    "Tau (delay): {round(vis_data[vis_eup]['tau_kd']*1000, 2)}±{round(vis_data[vis_eup]['sigma_tau_kd']*1000, 2)} days\n",
    "\n",
    "----------\n",
    "Derived variables\n",
    "\n",
    "Mean Subsidence Rate: {msr_disp}±{smsr_disp} mm/y \n",
    "Observation timespan: {round(vis_data[vis_eup]['timespan_ky']*1000, 3)} y ({round(vis_data[vis_eup]['oldest_observation_ky']*1000, 3)} - {round(vis_data[vis_eup]['oldest_observation_ky']*1000 + vis_data[vis_eup]['timespan_ky']*1000, 3)})\n",
    "# observations: {int(1000*vis_data[vis_eup]['n_observations_1000'])}\n",
    "\n",
    "----------\n",
    "Variances\n",
    "var(h0): {vis_data[vis_eup]['sigma_h2015_m']**2:.2E} m^2\n",
    "var(xI): {(vis_data[vis_eup]['sigma_xI_mpy']*1000)**2:.2E} mm^2/y^2\n",
    "var(xP): {(vis_data[vis_eup]['sigma_xP_mpmm']*1000)**2:.2E} mm^2/mm^2\n",
    "var(xE): {(vis_data[vis_eup]['sigma_xE_mpmm']*1000)**2:.2E} mm^2/mm^2\n",
    "var(tau): {(vis_data[vis_eup]['sigma_tau_kd']*1000)**2:.2E} days^2\n",
    "\n",
    "Covariances\n",
    "cov(h0, xI): {vis_data[vis_eup]['rho_h2015_xI_1000']*1000 * vis_data[vis_eup]['sigma_h2015_m'] * vis_data[vis_eup]['sigma_xI_mpy']*1000:.2E}\n",
    "cov(h0, xP): {vis_data[vis_eup]['rho_h2015_xP_1000']*1000 * vis_data[vis_eup]['sigma_h2015_m'] * vis_data[vis_eup]['sigma_xP_mpmm']*1000:.2E}\n",
    "cov(h0, xE): {vis_data[vis_eup]['rho_h2015_xE_1000']*1000 * vis_data[vis_eup]['sigma_h2015_m'] * vis_data[vis_eup]['sigma_xE_mpmm']*1000:.2E}\n",
    "cov(h0, tau): {vis_data[vis_eup]['rho_h2015_tau_1000']*1000 * vis_data[vis_eup]['sigma_h2015_m'] * vis_data[vis_eup]['sigma_tau_kd']*1000:.2E}\n",
    "cov(xI, xE): {vis_data[vis_eup]['rho_xI_xE_1000']*1000 * vis_data[vis_eup]['sigma_xI_mpy']*1000 * vis_data[vis_eup]['sigma_xE_mpmm']*1000:.2E}\n",
    "cov(xI, xP): {vis_data[vis_eup]['rho_xI_xP_1000']*1000 * vis_data[vis_eup]['sigma_xI_mpy']*1000 * vis_data[vis_eup]['sigma_xP_mpmm']*1000:.2E}\n",
    "cov(xI, tau): {vis_data[vis_eup]['rho_xI_tau_1000']*1000 * vis_data[vis_eup]['sigma_xI_mpy']*1000 * vis_data[vis_eup]['sigma_tau_kd']*1000:.2E}\n",
    "cov(xP, xE): {vis_data[vis_eup]['rho_xP_xE_1000']*1000 * vis_data[vis_eup]['sigma_xP_mpmm']*1000 * vis_data[vis_eup]['sigma_xE_mpmm']*1000:.2E}\n",
    "cov(xP, tau): {vis_data[vis_eup]['rho_xP_tau_1000']*1000 * vis_data[vis_eup]['sigma_xP_mpmm']*1000 * vis_data[vis_eup]['sigma_tau_kd']*1000:.2E}\n",
    "cov(xE, tau): {vis_data[vis_eup]['rho_xE_tau_1000']*1000 * vis_data[vis_eup]['sigma_xE_mpmm']*1000 * vis_data[vis_eup]['sigma_tau_kd']*1000:.2E}\n",
    "\n",
    "---------\n",
    "Statistics\n",
    "\n",
    "Significant mean subsidence rate detected: {\"No\" if vis_data[vis_eup]['significant_irreversible_subsidence_detected_2s_1000'] < 0.00001 else \"Yes\"} (alpha=0.05) / {\"No\" if vis_data[vis_eup]['significant_irreversible_subsidence_detected_3s_1000'] < 0.00001 else \"Yes\"} (alpha=0.01)\n",
    "Chosen mathematical model fits observations: {\"No\" if vis_data[vis_eup]['OMT_sust_2s_1000'] < 0.00001 else \"Yes\"} (alpha=0.05) / {\"No\" if vis_data[vis_eup]['OMT_sust_3s_1000'] < 0.00001 else \"Yes\"} (alpha=0.01) | Normalised F-value (T/nu) = {T_stat_norm:.2E}\n",
    "Discriminatory power of Mean Subsidence Rate: {round(vis_data[vis_eup]['discriminatory_power_2s_1000pct']*1000, 2)}% (alpha=0.05) / {round(vis_data[vis_eup]['discriminatory_power_3s_1000pct']*1000, 2)}% (alpha=0.01)\n",
    "Minimum Detectable Displacement Rate (80% confidence): {vis_data[vis_eup]['MDD_80p_mpy']*1000:.2E} mm/y\n",
    "\n",
    "---------\n",
    "Map link\n",
    "https://www.topotijdreis.nl/satelliet/2024/@{vis_data[vis_eup][\"center_dec\"][0]},{vis_data[vis_eup][\"center_dec\"][1]},11\n",
    "\n",
    "''')                            \n",
    "                    else: \n",
    "                        print(f'''GPKG spatial unit {EUP} (TXT {txt_eup}, VIS {vis_eup})\n",
    "----------\n",
    "Estimated parameters ({data['model_mode'] + ('-extended' if data['model_mode'] == 'SPAMS' else '')} model)\n",
    "\n",
    "Elevation (1 Jan 2015): {round(vis_data[vis_eup]['h2015_m'], 3)}±{round(vis_data[vis_eup]['sigma_h2015_m'], 3)} m - NAP\n",
    "XI (irreversible): {xi_disp}±{sxi_disp} mm/y ({round(vis_data[vis_eup]['xI_frac_1000pct']*1000, 1)}% active)\n",
    "----------\n",
    "Derived variables\n",
    "\n",
    "Mean Subsidence Rate: {msr_disp}±{smsr_disp} mm/y \n",
    "Observation timespan: {round(vis_data[vis_eup]['timespan_ky']*1000, 3)} y ({round(vis_data[vis_eup]['oldest_observation_ky']*1000, 3)} - {round(vis_data[vis_eup]['oldest_observation_ky']*1000 + vis_data[vis_eup]['timespan_ky']*1000, 3)})\n",
    "# observations: {int(1000*vis_data[vis_eup]['n_observations_1000'])}\n",
    "\n",
    "----------\n",
    "Variances\n",
    "var(h0): {vis_data[vis_eup]['sigma_h2015_m']**2:.2E} m^2\n",
    "var(xI): {(vis_data[vis_eup]['sigma_xI_mpy']*1000)**2:.2E} mm^2/y^2\n",
    "\n",
    "Covariances\n",
    "cov(h0, xI): {vis_data[vis_eup]['rho_h2015_xI_1000']*1000 * vis_data[vis_eup]['sigma_h2015_m'] * vis_data[vis_eup]['sigma_xI_mpy']*1000:.2E}\n",
    "\n",
    "---------\n",
    "Statistics\n",
    "\n",
    "Significant mean subsidence rate detected: {\"No\" if vis_data[vis_eup]['significant_irreversible_subsidence_detected_2s_1000'] < 0.00001 else \"Yes\"} (alpha=0.05) / {\"No\" if vis_data[vis_eup]['significant_irreversible_subsidence_detected_3s_1000'] < 0.00001 else \"Yes\"} (alpha=0.01)\n",
    "Chosen mathematical model fits observations: {\"No\" if vis_data[vis_eup]['OMT_sust_2s_1000'] < 0.00001 else \"Yes\"} (alpha=0.05) / {\"No\" if vis_data[vis_eup]['OMT_sust_3s_1000'] < 0.00001 else \"Yes\"} (alpha=0.01) | Normalised F-value (T/nu) = {T_stat_norm:.2E}\n",
    "Discriminatory power of Mean Subsidence Rate: {round(vis_data[vis_eup]['discriminatory_power_2s_1000pct']*1000, 2)}% (alpha=0.05) / {round(vis_data[vis_eup]['discriminatory_power_3s_1000pct']*1000, 2)}% (alpha=0.01)\n",
    "Minimum Detectable Displacement Rate (80% confidence): {vis_data[vis_eup]['MDD_80p_mpy']*1000:.2E} mm/y\n",
    "\n",
    "---------\n",
    "Map link\n",
    "https://www.topotijdreis.nl/satelliet/2024/@{vis_data[vis_eup][\"center_dec\"][0]},{vis_data[vis_eup][\"center_dec\"][1]},11\n",
    "''')\n",
    "            else:\n",
    "                nsigfig_xi_raw = np.log10(spams10_data[spams10_EUP]['sigma_xI_mpy']*1000)\n",
    "                if nsigfig_xi_raw < 0:\n",
    "                    nsigfig = int(np.ceil(-1 * nsigfig_xi_raw) + 1)\n",
    "                    xi_disp = round(spams10_data[spams10_EUP]['xI_mpy']*1000, nsigfig)\n",
    "                    sxi_disp = round(spams10_data[spams10_EUP]['sigma_xI_mpy']*1000, nsigfig)\n",
    "                    msr_disp = round(spams10_data[spams10_EUP]['mean_yearly_irreversible_subsidence_MYIS_mpy']*1000, nsigfig)\n",
    "                    smsr_disp = round(spams10_data[spams10_EUP]['sigma_MYIS_mpy']*1000, nsigfig)\n",
    "                elif nsigfig_xi_raw < 1:\n",
    "                    xi_disp = round(spams10_data[spams10_EUP]['xI_mpy']*1000, 1)\n",
    "                    sxi_disp = round(spams10_data[spams10_EUP]['sigma_xI_mpy']*1000, 1)\n",
    "                    msr_disp = round(spams10_data[spams10_EUP]['mean_yearly_irreversible_subsidence_MYIS_mpy']*1000, 1)\n",
    "                    smsr_disp = round(spams10_data[spams10_EUP]['sigma_MYIS_mpy']*1000, 1)\n",
    "                else:\n",
    "                    xi_disp = round(spams10_data[spams10_EUP]['xI_mpy']*1000, 0)\n",
    "                    sxi_disp = round(spams10_data[spams10_EUP]['sigma_xI_mpy']*1000, 0)  \n",
    "                    msr_disp = round(spams10_data[spams10_EUP]['mean_yearly_irreversible_subsidence_MYIS_mpy']*1000, 0)\n",
    "                    smsr_disp = round(spams10_data[spams10_EUP]['sigma_MYIS_mpy']*1000, 0)\n",
    "\n",
    "                nsigfig_xp_raw = np.log10(spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000)\n",
    "                if nsigfig_xp_raw < 0:\n",
    "                    nsigfig = int(np.ceil(-1 * nsigfig_xp_raw) + 1)\n",
    "                    xp_disp = round(spams10_data[spams10_EUP]['xP_mpmm']*1000, nsigfig)\n",
    "                    sxp_disp = round(spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000, nsigfig)\n",
    "                elif nsigfig_xp_raw < 1:\n",
    "                    xp_disp = round(spams10_data[spams10_EUP]['xP_mpmm']*1000, 1)\n",
    "                    sxp_disp = round(spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000, 1)\n",
    "                else:\n",
    "                    xp_disp = round(spams10_data[spams10_EUP]['xP_mpmm']*1000, 0)\n",
    "                    sxp_disp = round(spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000, 0)  \n",
    "\n",
    "                nsigfig_xe_raw = np.log10(spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000)\n",
    "                if nsigfig_xe_raw < 0:\n",
    "                    nsigfig = int(np.ceil(-1 * nsigfig_xe_raw) + 1)\n",
    "                    xe_disp = round(spams10_data[spams10_EUP]['xE_mpmm']*1000, nsigfig)\n",
    "                    sxe_disp = round(spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000, nsigfig)\n",
    "                elif nsigfig_xe_raw < 1:\n",
    "                    xe_disp = round(spams10_data[spams10_EUP]['xE_mpmm']*1000, 1)\n",
    "                    sxe_disp = round(spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000, 1)\n",
    "                else:\n",
    "                    xe_disp = round(spams10_data[spams10_EUP]['xE_mpmm']*1000, 0)\n",
    "                    sxe_disp = round(spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000, 0) \n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                print(f'''SPAMS10 spatial unit {EUP}\n",
    "----------\n",
    "Estimated parameters ({data['model_mode'] + ('-extended' if data['model_mode'] == 'SPAMS' else '')} model)\n",
    "\n",
    "XI (irreversible): {xi_disp}±{sxi_disp} mm/y ({round(spams10_data[spams10_EUP]['xI_frac_1000pct']*1000, 1)}% active)\n",
    "XP (precipitation): {xp_disp}±{sxp_disp} mm/mm\n",
    "XE (evapotranspiration): {xe_disp}±{sxe_disp} mm/mm\n",
    "\n",
    "----------\n",
    "Fixed parameter\n",
    "Tau (delay): {round(spams10_data[spams10_EUP]['tau_kd']*1000, 2)} days\n",
    "\n",
    "----------\n",
    "Derived variables\n",
    "\n",
    "Mean Subsidence Rate: {msr_disp}±{smsr_disp} mm/y \n",
    "Observation timespan: Unknown\n",
    "# observations: {int(spams10_data[spams10_EUP]['n_observations_1000'])}\n",
    "\n",
    "----------\n",
    "Variances\n",
    "var(xI): {(spams10_data[spams10_EUP]['sigma_xI_mpy']*1000)**2:.2E} mm^2/y^2\n",
    "var(xP): {(spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000)**2:.2E} mm^2/mm^2\n",
    "var(xE): {(spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000)**2:.2E} mm^2/mm^2\n",
    "\n",
    "Covariances\n",
    "cov(xI, xE): {spams10_data[spams10_EUP]['rho_xI_xE_1000']*1000 * spams10_data[spams10_EUP]['sigma_xI_mpy']*1000 * spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000:.2E}\n",
    "cov(xI, xP): {spams10_data[spams10_EUP]['rho_xI_xP_1000']*1000 * spams10_data[spams10_EUP]['sigma_xI_mpy']*1000 * spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000:.2E}\n",
    "cov(xP, xE): {spams10_data[spams10_EUP]['rho_xP_xE_1000']*1000 * spams10_data[spams10_EUP]['sigma_xP_mpmm']*1000 * spams10_data[spams10_EUP]['sigma_xE_mpmm']*1000:.2E}\n",
    "\n",
    "---------\n",
    "Statistics\n",
    "\n",
    "RSS: {round(spams10_data[spams10_EUP][\"rss\"], 2)}\n",
    "\n",
    "---------\n",
    "Map link\n",
    "https://www.topotijdreis.nl/satelliet/2024/@{spams10_data[spams10_EUP][\"center_dec\"][0]},{spams10_data[spams10_EUP]['center_dec'][1]},11\n",
    "''')\n",
    "            \n",
    "    return button_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144d4dd-3180-402f-9aee-4fe1c2af8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "eup_idx = []\n",
    "eup_polys = []\n",
    "eup_layer_groups = [LayerGroup()]\n",
    "ct = 0\n",
    "MAX_GROUP_SIZE = 250\n",
    "\n",
    "print(\"Adding D-DEM...\")\n",
    "for EUP in list(gpkg_data.keys()):\n",
    "    try:\n",
    "        vis_eup = map_vis_index(EUP)\n",
    "        if vis_eup is None:\n",
    "            continue\n",
    "\n",
    "        polygon = Polygon(\n",
    "            locations = gpkg_data[EUP]['crd_wgs'],\n",
    "            weight=0,\n",
    "            fill_color='black',\n",
    "            fill_opacity=1)\n",
    "        polygon.on_click(plot_data(EUP, m=m))\n",
    "        eup_polys.append(polygon)\n",
    "        eup_layer_groups[-1].add_layer(eup_polys[-1])\n",
    "        eup_idx.append(vis_eup)\n",
    "        ct += 1\n",
    "        if ct % MAX_GROUP_SIZE == 0:\n",
    "            m.add_layer(eup_layer_groups[-1])\n",
    "            eup_layer_groups.append(LayerGroup())\n",
    "        if ct % 1000 == 0:\n",
    "            print(f\"{ct}/{len(list(gpkg_data.keys()))} done...\")\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "print(\"Adding SPAMS10...\")\n",
    "for spams10_EUP in list(spams10_data.keys()):\n",
    "    polygon = Polygon(\n",
    "        locations = [[spams10_data[spams10_EUP][\"pnt_crd\"][1]+3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]+3e-4],\n",
    "                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]-3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]+3e-4],\n",
    "                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]-3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]-3e-4],\n",
    "                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]+3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]-3e-4],\n",
    "                     [spams10_data[spams10_EUP][\"pnt_crd\"][1]+3e-4, spams10_data[spams10_EUP][\"pnt_crd\"][0]+3e-4]],\n",
    "        weight=1,\n",
    "        color=\"black\",\n",
    "        fill_color='black',\n",
    "        fill_opacity=1)\n",
    "    polygon.on_click(plot_data(f\"SPAMS10_{spams10_EUP}\", m=m))\n",
    "    eup_polys.append(polygon)\n",
    "    eup_layer_groups[-1].add_layer(eup_polys[-1])\n",
    "    eup_idx.append(f\"SPAMS10_{spams10_EUP}\")\n",
    "    ct += 1\n",
    "    if ct % MAX_GROUP_SIZE == 0:\n",
    "        m.add_layer(eup_layer_groups[-1])\n",
    "        eup_layer_groups.append(LayerGroup())\n",
    "    if ct % 1000 == 0:\n",
    "        print(f\"{ct}/{len(list(gpkg_data.keys()))+len(list(spams10_data.keys()))} done...\")\n",
    "\n",
    "m.add_layer(eup_layer_groups[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cd45f-baf3-4e74-b44f-25f9fef4ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_layer(AoI)\n",
    "m.add_layer(highlighter_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f589ab8-a902-4d15-90a0-3da77a756fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eup_idx), len(eup_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7af8b9-b0ab-4471-9711-5b1cac7269a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c932f94-df4d-4e03-8915-e3f7cdd2e4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7f6a4-412c-4c51-b339-ec45cf53cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overview(plot='Mean Subsidence Rate (MSR)'):\n",
    "    highlighter.locations = [(0,0), (0,0)]\n",
    "    #with output:\n",
    "    #    clear_output(wait=True)\n",
    "    #    display(main_plot)\n",
    "    if plot != 'Select':\n",
    "        vdir = {\n",
    "            'Mean Subsidence Rate (MSR)': [-10, 10, \"mm/y\", \"both\"],\n",
    "            'Mean Subsidence Rate Standard Deviation': [0, 10, \"mm/y\", \"max\"],\n",
    "            'Elevation at 1 Jan 2015': [-8, 2, \"m\", \"both\"],\n",
    "            'Elevation at 1 Jan 2015 Standard Deviation': [0, 10, \"cm\", \"max\"],\n",
    "            'Number of Observations': [0, 20, \"#\", \"max\"],\n",
    "            'Timespan': [0, 60, \"y\", \"max\"],\n",
    "            'xI': [-10, 10, \"mm/y\", \"both\"],\n",
    "            'xI Standard Deviation': [0, 10, \"mm/y\", \"max\"],\n",
    "            'Irreversible subsidence active fraction': [0, 100, \"%\", \"neither\"],\n",
    "            'xP': [0, 0.15, \"mm/mm\", \"max\"],\n",
    "            'xP Standard Deviation': [0, 0.01, \"mm/mm\", \"max\"],\n",
    "            'xE': [0, 0.15, \"mm/mm\", \"max\"],\n",
    "            'xE Standard Deviation': [0, 0.01, \"mm/mm\", \"max\"],\n",
    "            'Tau': [0, 100, \"days\", \"max\"],\n",
    "            'Tau Standard Deviation': [0, 1, \"days\", \"max\"],\n",
    "            'Significant MSR detected (alpha=0.05)': [0, 1, \"No < > Yes\", 'neither'], \n",
    "            'Significant MSR detected (alpha=0.01)': [0, 1, \"No < > Yes\", 'neither'], \n",
    "            'Model Fits Observations (alpha=0.05)': [0, 1, \"No < > Yes\", 'neither'], \n",
    "            'Model Fits Observations (alpha=0.01)': [0, 1, \"No < > Yes\", 'neither'], \n",
    "            'Model Fit Normalized F-value': [0.5, 1.5, \"-\", \"both\"],\n",
    "            'MSR Discriminatory Power (alpha=0.05)': [0, 100, \"%\", 'neither'], \n",
    "            'MSR Discriminatory Power (alpha=0.01]':[0, 100, \"%\", 'neither'], \n",
    "            'Min Det. Displacement Rate (80% confidence)': [0, 2, \"mm/y\", \"max\"],\n",
    "            \"First observation\": [1950, 2010, \"y\", \"both\"]\n",
    "       }\n",
    "        vis_layer_translations = {\n",
    "            'Mean Subsidence Rate (MSR)': ['mean_yearly_irreversible_subsidence_MYIS_mpy', 1000],\n",
    "            'Mean Subsidence Rate Standard Deviation': ['sigma_MYIS_mpy', 1000],\n",
    "            'Elevation at 1 Jan 2015': ['h2015_m', 1],\n",
    "            'Elevation at 1 Jan 2015 Standard Deviation': ['sigma_h2015_m', 100],\n",
    "            'Number of Observations': ['n_observations_1000', 1000],\n",
    "                'Timespan': ['timespan_kd', 1000],\n",
    "                'xI': ['xI_mpy', 1000],\n",
    "                'xI Standard Deviation': ['sigma_xI_mpy', 1000],\n",
    "                'Irreversible subsidence active fraction': ['xI_frac_1000pct', 1000],\n",
    "                'xP': [\"xP_mpmm\", 1000],\n",
    "                'xP Standard Deviation': [\"sigma_xP_mpmm\", 1000],\n",
    "                'xE': [\"xE_mpmm\", 1000],\n",
    "                'xE Standard Deviation': [\"sigma_xE_mpmm\", 1000],\n",
    "                'Tau': [\"tau_kd\", 1000],\n",
    "                'Tau Standard Deviation': [\"sigma_tau_kd\", 1000],\n",
    "                'Significant MSR detected (alpha=0.05)': [\"significant_irreversible_subsidence_detected_2s_1000\", 1000], \n",
    "                'Significant MSR detected (alpha=0.01)': [\"significant_irreversible_subsidence_detected_3s_1000\", 1000], \n",
    "                'Model Fits Observations (alpha=0.05)': [\"OMT_sust_2s_1000\", 1000], \n",
    "                'Model Fits Observations (alpha=0.01)': [\"OMT_sust_3s_1000\", 1000], \n",
    "                'MSR Discriminatory Power (alpha=0.05)': [\"discriminatory_power_2s_1000pct\", 1000], \n",
    "                'MSR Discriminatory Power (alpha=0.01]':[\"discriminatory_power_3s_1000pct\", 1000], \n",
    "                'Model Fit Normalized F-value': [\"F_value_norm\", 1],\n",
    "                'Min Det. Displacement Rate (80% confidence)': [\"MDD_80p_mpy\", 1000],\n",
    "                'First observation': [\"oldest_observation_ky\", 1000],\n",
    "        }\n",
    "                    \n",
    "        #with output:\n",
    "        if True:\n",
    "            \n",
    "            def update_data(b):\n",
    "                with out4:\n",
    "                    print(f'Should remove {b.description.split(\" \")[-1]}')\n",
    "\n",
    "            #display(tab2)\n",
    "            #display(tab)\n",
    "            #display(tab3)\n",
    "            \n",
    "            ct = 0\n",
    "\n",
    "            with out5:\n",
    "                try:\n",
    "                    plt.close(fig=\"Map colorbar\")\n",
    "                except:\n",
    "                    pass\n",
    "                clear_output(wait=True)\n",
    "                fig, ax = plt.subplots(figsize=(10,2), num=\"Map colorbar\")\n",
    "                #ax.axis('off')\n",
    "                colmap1 = mpl.colors.LinearSegmentedColormap.from_list(\"custom_gradient\", [\"#ff0000\", \"#ffffff\", \"#0000ff\"])\n",
    "                cbar = matplotlib.colorbar.ColorbarBase(ax, cmap=colmap1, orientation = 'horizontal',extend=vdir[plot][3], \n",
    "                                norm=mpl.colors.Normalize(vmin=vdir[plot][0],vmax=vdir[plot][1]))\n",
    "                cbar.set_label(f\"{plot} [{vdir[plot][2]}]\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            for n_eup, vis_eup in enumerate(eup_idx):\n",
    "                if isinstance(vis_eup, str):\n",
    "                    given_val = spams10_data[int(vis_eup.split(\"_\")[1])][vis_layer_translations[plot][0]]\n",
    "                    if given_val is not None:\n",
    "                        val = given_val * vis_layer_translations[plot][1]\n",
    "                        eup_polys[n_eup].fill_color = convert_value_to_hex(val, vdir[plot][0], vdir[plot][1])\n",
    "                    else:\n",
    "                        eup_polys[n_eup].fill_color = \"#000000\"\n",
    "                else:                \n",
    "                    val = vis_data[vis_eup][vis_layer_translations[plot][0]] * vis_layer_translations[plot][1]\n",
    "                    eup_polys[n_eup].fill_color = convert_value_to_hex(val, vdir[plot][0], vdir[plot][1])\n",
    "                if n_eup % 250 == 0:\n",
    "                    with out1:\n",
    "                        clear_output(wait=True)\n",
    "                        print(f'Loading spatial units ({n_eup}/{len(eup_idx)})...')\n",
    "                    t.sleep(0.25)  # otherwise the data rate becomes too high for the map to render\n",
    "            \n",
    "            with out1:\n",
    "                clear_output(wait=True)\n",
    "                print('Loaded spatial units!')\n",
    "                print(f'Click to analyse a spatial unit')\n",
    "            with out2:\n",
    "                clear_output(wait=True)\n",
    "                print('Loaded spatial units!')\n",
    "                print(f'Click to analyse a spatial unit')\n",
    "            with out3:\n",
    "                clear_output(wait=True)\n",
    "                print('Loaded spatial units!')\n",
    "                print(f'Click to analyse a spatial unit')\n",
    "            with out4:\n",
    "                clear_output(wait=True)\n",
    "                print('Loaded spatial units!')\n",
    "                print(f'Click to analyse a spatial unit')\n",
    "\n",
    "            #display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff631c-d891-4abe-acbf-12a393cda768",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_drop = widgets.Dropdown(\n",
    "        options=['Select', \n",
    "                 'Mean Subsidence Rate (MSR)', \n",
    "                 'Mean Subsidence Rate Standard Deviation', \n",
    "                 'Elevation at 1 Jan 2015', \n",
    "                 'Elevation at 1 Jan 2015 Standard Deviation',\n",
    "                 'Number of Observations',\n",
    "                'Timespan',\n",
    "                'xI',\n",
    "                'xI Standard Deviation',\n",
    "                \"Irreversible subsidence active fraction\",\n",
    "                'xP',\n",
    "                'xP Standard Deviation',\n",
    "                'xE',\n",
    "                'xE Standard Deviation',\n",
    "                'Tau',\n",
    "                'Tau Standard Deviation',\n",
    "                'Significant MSR detected (alpha=0.05)',\n",
    "                'Significant MSR detected (alpha=0.01)',\n",
    "                'Model Fits Observations (alpha=0.05)',\n",
    "                'Model Fits Observations (alpha=0.01)',\n",
    "                # 'Model Fit Normalized F-value',\n",
    "                'MSR Discriminatory Power (alpha=0.05)',\n",
    "                'MSR Discriminatory Power (alpha=0.01]',\n",
    "                'Min Det. Displacement Rate (80% confidence)',\n",
    "                 \"First observation\",\n",
    "                ],\n",
    "        value='Select',\n",
    "        description='Parameter:',\n",
    "        disabled=False,\n",
    "    )\n",
    "main_plot = interactive(plot_overview, plot=plot_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b174b3-5ee8-461e-a601-fcc2b1f88f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box_text = widgets.Text(\n",
    "    placeholder=\"Enter Parcel Number (VIS / SPAMS10 ID)\",\n",
    "    disabled=False\n",
    ")\n",
    "search_button = widgets.Button(description=\"Search\")\n",
    "\n",
    "def search_click(b):\n",
    "    if search_box_text.value.isnumeric():\n",
    "        num = eval(search_box_text.value)\n",
    "\n",
    "        with out6:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Search on VIS ID (numbers) or SPAMS10-ID (SPAMS10_###)\")\n",
    "            display(search_box_text)\n",
    "            display(search_button)\n",
    "        if num in eup_idx:\n",
    "            gpkg_num = None\n",
    "            for key in GPKG_VIS_MAP.keys():\n",
    "                if GPKG_VIS_MAP[key] == num:\n",
    "                    gpkg_num = key\n",
    "                    break\n",
    "            if gpkg_num is not None:\n",
    "                plot_data(gpkg_num, m=m)()\n",
    "                txt_eup = map_index(gpkg_num)\n",
    "                with out6:\n",
    "                    print(f\"Found VIS Spatial Unit {num} (GPKG ID {gpkg_num}, TXT ID {txt_eup})\")\n",
    "                EUP_f = open(f'Data/EUPs/{txt_eup}.txt')\n",
    "                raw = EUP_f.read()\n",
    "                EUP_f.close()\n",
    "                raw_EUP = raw.replace('nan', \"'nan'\").replace('array', 'np.array')\n",
    "                data = eval(raw_EUP)\n",
    "                crds = convert_rd_to_wgs84(data['crd_dec'][0])\n",
    "                mean_crds = [np.mean([i[0] for i in crds]), np.mean([i[1] for i in crds])]\n",
    "                m.center = mean_crds\n",
    "            else:\n",
    "                with out6:\n",
    "                    print(\"ERROR: VIS ID provided is invalid\")\n",
    "        else:\n",
    "            with out6:\n",
    "                print(\"ERROR: VIS ID provided is invalid\")\n",
    "    else:\n",
    "        with out6:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Search on VIS ID (numbers) or SPAMS10-ID (SPAMS10_###)\")\n",
    "            display(search_box_text)\n",
    "            display(search_button)\n",
    "        if search_box_text.value in eup_idx:\n",
    "            plot_data(search_box_text.value, m=m)()\n",
    "            spams10_id = eval(search_box_text.value.split(\"_\")[1])\n",
    "            m.center = [spams10_data[spams10_id][\"pnt_crd\"][1], spams10_data[spams10_id][\"pnt_crd\"][0]]\n",
    "            with out6:\n",
    "                print(f\"Found SPAMS10 spatial unit {spams10_id}!\")\n",
    "        else:\n",
    "            with out6:\n",
    "                print(f\"ERROR: SPAMS10 ID '{search_box_text.value}' is invalid. Make sure to follow the format SPAMS10_###\")        \n",
    "\n",
    "search_button.on_click(search_click)\n",
    "\n",
    "with out6:\n",
    "    print(\"Search on VIS ID (numbers) or SPAMS10-ID (SPAMS10_###)\")\n",
    "    display(search_box_text)\n",
    "    display(search_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a6f7d-7a9c-4a4f-8b0a-fa1406fdcccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "button = widgets.Button(description=\"Run Me!\")\n",
    "\n",
    "\n",
    "display(button, output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        display(main_plot)\n",
    "        \n",
    "button.on_click(on_button_clicked)\n",
    "display(tab4)\n",
    "display(tab2)\n",
    "display(tab)\n",
    "display(tab3)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f7fca-0282-4a5f-aa01-84717e5148d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba92be5-c130-4ee7-9e1b-42587e5dc6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
